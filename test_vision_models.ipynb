{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd88fd8adee4072b3689b33f6836218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/240 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dade59a155242dabbd0af3af0094eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c58d97ee8444d0adbb8583dc1b6163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/787M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "\n",
    "# microsoft/swinv2-tiny-patch4-window8-256: latentdim = 768, 28M params\n",
    "# microsoft/swinv2-base-patch4-window12to16-192to256-22kto1k-ft = 1024, 88M params\n",
    "# microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft = 1536, 197M params\n",
    "# microsoft/swinv2-large-patch4-window12to24-192to384-22kto1k-ft = 1536, 197M params\n",
    "\n",
    "MODEL = \"microsoft/swinv2-large-patch4-window12to24-192to384-22kto1k-ft\"\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL)\n",
    "img = Image.open(\"test.png\").convert(\"RGB\")\n",
    "inputs = processor(img, return_tensors=\"pt\")\n",
    "model = AutoModel.from_pretrained(MODEL)\n",
    "outputs = model(**inputs)\n",
    "outputs.pooler_output.shape\n",
    "print(model.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluate-cbr-Epwt-pU6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
